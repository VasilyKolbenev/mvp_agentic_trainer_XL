# üóÑÔ∏è –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ClickHouse (ECK_Logs)

**–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –ª–æ–≥–æ–≤ ESK**

---

## üèóÔ∏è –ü–æ–ª–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å ClickHouse

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              –ó–∞–∫—Ä—ã—Ç—ã–π –∫–æ–Ω—Ç—É—Ä (–≤–∞—à–∞ —Å–µ—Ç—å)                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ
‚îÇ  ‚îÇ  ECK_Logs    ‚îÇ –õ–æ–≥–∏ –∫–æ–Ω—Ç–∞–∫—Ç-—Ü–µ–Ω—Ç—Ä–∞                   ‚îÇ
‚îÇ  ‚îÇ (ClickHouse) ‚îÇ                                        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                        ‚îÇ
‚îÇ         ‚îÇ SQL Export                                     ‚îÇ
‚îÇ         ‚ñº                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ
‚îÇ  ‚îÇ  API Service ‚îÇ FastAPI + ClickHouse Connector        ‚îÇ
‚îÇ  ‚îÇ  (FastAPI)   ‚îÇ                                        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                        ‚îÇ
‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ         ‚ñº                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ     ML Data Pipeline                      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ETL ‚Üí Labeler ‚Üí Augmenter ‚Üí QC ‚Üí ...    ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ         ‚ñº                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ LLM Mistral  ‚îÇ         ‚îÇ  LLM Qwen    ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ (Labeler)    ‚îÇ         ‚îÇ (Augmenter)  ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–í—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏ –≤–∞—à–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã!** üîí

---

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞

### 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ClickHouse

–í `.env` –¥–æ–±–∞–≤—å—Ç–µ:

```env
# ===== ClickHouse (ECK_Logs) =====
CLICKHOUSE_HOST=clickhouse.your-domain.local
CLICKHOUSE_PORT=8123
CLICKHOUSE_USERNAME=default
CLICKHOUSE_PASSWORD=your-secure-password
CLICKHOUSE_DATABASE=esk

# –¢–∞–±–ª–∏—Ü–∞ –∏ –∫–æ–ª–æ–Ω–∫–∏
CLICKHOUSE_TABLE=logs
CLICKHOUSE_TEXT_COLUMN=query_text
CLICKHOUSE_DOMAIN_COLUMN=domain
CLICKHOUSE_TIMESTAMP_COLUMN=created_at
CLICKHOUSE_USER_ID_COLUMN=user_id
```

---

### 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ

```python
from src.clickhouse_connector import ClickHouseConnector, ClickHouseConfig
from src.pipeline import ETLProcessor, LabelerAgent

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
ch_config = ClickHouseConfig(
    host=os.getenv("CLICKHOUSE_HOST"),
    port=int(os.getenv("CLICKHOUSE_PORT", 8123)),
    username=os.getenv("CLICKHOUSE_USERNAME"),
    password=os.getenv("CLICKHOUSE_PASSWORD"),
    database=os.getenv("CLICKHOUSE_DATABASE"),
    table_name=os.getenv("CLICKHOUSE_TABLE"),
)

connector = ClickHouseConnector(ch_config)

# –í—ã–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
df = connector.fetch_logs(days=7, limit=10000)

# –ü–µ—Ä–µ–¥–∞—á–∞ –≤ pipeline
etl = ETLProcessor()
# df —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è ETL
processed_df = etl.process_file(...)  # –∏–ª–∏ —Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å df

# –î–∞–ª–µ–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
labeler = LabelerAgent(config)
results = await labeler.classify_dataframe(df)
```

---

### 3. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ endpoint –≤ API

–î–æ–±–∞–≤—å—Ç–µ –≤ `src/api.py`:

```python
from .clickhouse_connector import ClickHouseConnector, ClickHouseConfig

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä
clickhouse_connector = None

def init_clickhouse():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ClickHouse connector"""
    global clickhouse_connector
    
    if os.getenv("CLICKHOUSE_HOST"):
        config = ClickHouseConfig(
            host=os.getenv("CLICKHOUSE_HOST"),
            port=int(os.getenv("CLICKHOUSE_PORT", 8123)),
            username=os.getenv("CLICKHOUSE_USERNAME", "default"),
            password=os.getenv("CLICKHOUSE_PASSWORD", ""),
            database=os.getenv("CLICKHOUSE_DATABASE", "default"),
            table_name=os.getenv("CLICKHOUSE_TABLE", "esk_logs"),
        )
        
        clickhouse_connector = ClickHouseConnector(config)
        if clickhouse_connector.connect():
            logger.info("ClickHouse connector initialized")
        else:
            logger.warning("ClickHouse connection failed")

@app.on_event("startup")
async def startup_event():
    init_components()
    init_clickhouse()  # ‚Üê –î–æ–±–∞–≤–∏—Ç—å

# –ù–æ–≤—ã–π endpoint
@app.post("/fetch-from-clickhouse")
async def fetch_from_clickhouse(
    days: int = 7,
    limit: Optional[int] = None,
    process: bool = True
):
    """
    –í—ã–≥—Ä—É–∂–∞–µ—Ç –ª–æ–≥–∏ –∏–∑ ClickHouse –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç.
    
    Args:
        days: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏
        limit: –º–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–æ–∫
        process: —Å—Ä–∞–∑—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ pipeline
    """
    
    if not clickhouse_connector:
        raise HTTPException(
            status_code=503,
            detail="ClickHouse not configured"
        )
    
    # –í—ã–≥—Ä—É–∑–∫–∞
    df = clickhouse_connector.fetch_logs(days=days, limit=limit)
    
    if df.empty:
        raise HTTPException(
            status_code=404,
            detail="No data found in ClickHouse"
        )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    temp_path = Path("data/uploads/clickhouse_export.csv")
    temp_path.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(temp_path, index=False)
    
    response = {
        "status": "success",
        "rows_fetched": len(df),
        "file_path": str(temp_path),
    }
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - —Å—Ä–∞–∑—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
    if process:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π pipeline
        # ... (–∫–æ–¥ –∏–∑ /process endpoint)
        pass
    
    return response
```

---

## üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ (Scheduled)

### Docker Compose —Å cron job:

```yaml
services:
  ml-pipeline:
    # ... –æ—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å
  
  clickhouse-fetcher:
    build: .
    command: python -m src.scheduled_fetcher
    environment:
      - CLICKHOUSE_HOST=clickhouse.local
      - CLICKHOUSE_DATABASE=esk
      - FETCH_INTERVAL_HOURS=6  # –ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
    depends_on:
      - ml-pipeline
```

### –°–∫—Ä–∏–ø—Ç `src/scheduled_fetcher.py`:

```python
import asyncio
import os
from datetime import datetime
from pathlib import Path

from .clickhouse_connector import ClickHouseConnector, ClickHouseConfig

async def scheduled_fetch():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –∏–∑ ClickHouse"""
    
    config = ClickHouseConfig(
        host=os.getenv("CLICKHOUSE_HOST"),
        port=int(os.getenv("CLICKHOUSE_PORT", 8123)),
        username=os.getenv("CLICKHOUSE_USERNAME", "default"),
        password=os.getenv("CLICKHOUSE_PASSWORD", ""),
        database=os.getenv("CLICKHOUSE_DATABASE", "esk"),
    )
    
    connector = ClickHouseConnector(config)
    interval_hours = int(os.getenv("FETCH_INTERVAL_HOURS", 6))
    
    while True:
        print(f"[{datetime.now()}] Fetching logs from ClickHouse...")
        
        # –í—ã–≥—Ä—É–∑–∫–∞
        df = connector.fetch_logs(days=1, limit=10000)
        
        if not df.empty:
            # –≠–∫—Å–ø–æ—Ä—Ç
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = Path(f"data/uploads/clickhouse_{timestamp}.csv")
            
            connector.export_to_file(output_file, days=1, format="csv")
            
            print(f"‚úÖ Exported {len(df)} rows to {output_file}")
            
            # TODO: –í—ã–∑–≤–∞—Ç—å API –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            # requests.post("http://ml-pipeline:8000/process", ...)
        
        # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –≤—ã–≥—Ä—É–∑–∫–∏
        await asyncio.sleep(interval_hours * 3600)

if __name__ == "__main__":
    asyncio.run(scheduled_fetch())
```

---

## üìä –ü—Ä–∏–º–µ—Ä SQL –∑–∞–ø—Ä–æ—Å–∞

### –¢–∞–±–ª–∏—Ü–∞ –≤ ClickHouse (–ø—Ä–∏–º–µ—Ä):

```sql
CREATE TABLE esk.logs (
    id UInt64,
    query_text String,
    domain Nullable(String),
    created_at DateTime,
    user_id Nullable(String),
    session_id Nullable(String),
    confidence Nullable(Float32)
) ENGINE = MergeTree()
ORDER BY created_at;
```

### –í—ã–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ–≤:

```sql
-- –õ–æ–≥–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–∫–∞–º–∏
SELECT 
    query_text as text,
    domain,
    created_at as ts,
    user_id
FROM esk.logs
WHERE created_at >= today() - 7
  AND length(query_text) > 3
ORDER BY created_at DESC
LIMIT 10000;
```

---

## üéØ –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã

### –†–µ–∂–∏–º 1: –†—É—á–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞

```bash
# 1. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –∏–∑ ClickHouse –≤ CSV
clickhouse-client --query "SELECT ... FROM esk.logs" --format CSV > logs.csv

# 2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —á–µ—Ä–µ–∑ API
curl -X POST http://localhost:8080/upload -F "file=@logs.csv"

# 3. –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ
curl -X POST http://localhost:8080/process -d '{...}'
```

---

### –†–µ–∂–∏–º 2: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —á–µ—Ä–µ–∑ –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä

```bash
# API endpoint –¥–ª—è –ø—Ä—è–º–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –∏–∑ ClickHouse
curl -X POST "http://localhost:8080/fetch-from-clickhouse?days=7&process=true"
```

---

### –†–µ–∂–∏–º 3: Scheduled (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π)

```yaml
# docker-compose.yml —Å cron job
services:
  clickhouse-fetcher:
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–∞–µ—Ç –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
```

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### –í –∑–∞–∫—Ä—ã—Ç–æ–º –∫–æ–Ω—Ç—É—Ä–µ:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Å–µ—Ç—å (VPN/LAN)        ‚îÇ
‚îÇ                                      ‚îÇ
‚îÇ  ClickHouse ‚îÄ‚îÄ‚ñ∂ API ‚îÄ‚îÄ‚ñ∂ Pipeline    ‚îÇ
‚îÇ      ‚ñ≤                    ‚îÇ          ‚îÇ
‚îÇ      ‚îÇ                    ‚ñº          ‚îÇ
‚îÇ  ESK Logs            LLM Models      ‚îÇ
‚îÇ                   (Mistral/Qwen)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

NO external connections! üîê
```

### .env –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:

```env
# ClickHouse (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ö–æ—Å—Ç)
CLICKHOUSE_HOST=clickhouse.internal.local
CLICKHOUSE_PORT=8123
CLICKHOUSE_USERNAME=pipeline_user
CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}  # –ò–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤

# LLM (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã)
LLM_LABELER_API_BASE=http://llm-mistral.internal:8000/v1
LLM_AUGMENTER_API_BASE=http://llm-qwen.internal:8001/v1
```

---

## ‚úÖ –ì–æ—Ç–æ–≤–æ!

**ClickHouse –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:**

- ‚úÖ –ö–æ–Ω–Ω–µ–∫—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω (`src/clickhouse_connector.py`)
- ‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ (`clickhouse-connect`)
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞
- ‚úÖ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- ‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ (ECK_Logs –∏–∑ ClickHouse)

**–¢–µ–ø–µ—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ: ClickHouse ‚Üí API ‚Üí ETL ‚Üí Pipeline! üéØ**

