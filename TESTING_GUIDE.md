# üß™ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é

–ù–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å ML Data Pipeline v2.0

---

## 1Ô∏è‚É£ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (Python)

### –ó–∞–ø—É—Å–∫:

```bash
python test_pipeline.py
```

### –ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è:

- ‚úÖ –ò–º–ø–æ—Ä—Ç—ã –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ .env
- ‚úÖ ETL –æ–±—Ä–∞–±–æ—Ç–∫–∞
- ‚úÖ Labeler –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
- ‚úÖ Quality Control (cosine + Levenshtein)
- ‚úÖ DataWriter —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- ‚úÖ DataStorage –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

```
üß™ ML DATA PIPELINE - –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
====================================

‚úÖ –í—Å–µ –∏–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã
‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞
‚úÖ ETL: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ 3 —Å—Ç—Ä–æ–∫
‚úÖ Labeler: –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ 2 —Ç–µ–∫—Å—Ç–æ–≤
‚úÖ Quality Control —Ä–∞–±–æ—Ç–∞–µ—Ç
‚úÖ DataWriter: train=4, eval=1
‚úÖ DataStorage: version v1.0.0 created

üéâ –í–°–ï –¢–ï–°–¢–´ –£–°–ü–ï–®–ù–û –ü–†–û–ô–î–ï–ù–´!
```

**–í—Ä–µ–º—è:** ~30-60 —Å–µ–∫—É–Ω–¥ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç LLM)

---

## 2Ô∏è‚É£ –¢–µ—Å—Ç API endpoints (Bash)

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:
API –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω:

```bash
# Docker
docker-compose up -d

# –ò–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ
python -m uvicorn src.api:app
```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤:

```bash
chmod +x test_api.sh
./test_api.sh
```

### –ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è:

- ‚úÖ `/` - –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
- ‚úÖ `/health` - health check
- ‚úÖ `/classify` - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
- ‚úÖ `/versions` - —Å–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π
- ‚úÖ `/stats` - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- ‚úÖ `/upload` - –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å test_logs.csv)
- ‚úÖ `/process` - –ø–æ–ª–Ω—ã–π pipeline

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

```
üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ML Data Pipeline API

1Ô∏è‚É£  –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...
‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω

–¢–µ—Å—Ç: –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
‚úÖ OK (HTTP 200)
{
  "service": "ESK ML Data Pipeline API",
  "version": "2.0.0",
  "status": "running"
}

–¢–µ—Å—Ç: Health Check
‚úÖ OK (HTTP 200)
{
  "status": "healthy",
  "components": {
    "etl": "ok",
    "labeler": "ok",
    ...
  }
}

üéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
```

---

## 3Ô∏è‚É£ –¢–µ—Å—Ç —á–µ—Ä–µ–∑ Swagger UI

### –ó–∞–ø—É—Å–∫:

1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ API:
   ```bash
   docker-compose up -d
   ```

2. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä:
   ```
   http://localhost:8000/docs
   ```

3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ endpoints —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π UI:
   - `POST /classify` - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç
   - `GET /stats` - –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
   - `GET /versions` - —Å–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ:** –í–∏–∑—É–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, –º–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Ä—É—á–Ω—É—é

---

## 4Ô∏è‚É£ –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline (Python —Å–∫—Ä–∏–ø—Ç)

### –°–æ–∑–¥–∞–π—Ç–µ `test_full_flow.py`:

```python
import asyncio
import requests
from pathlib import Path

async def test_full_pipeline():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline —á–µ—Ä–µ–∑ API"""
    
    base_url = "http://localhost:8000"
    
    print("üß™ –ü–æ–ª–Ω—ã–π pipeline —Ç–µ—Å—Ç\n")
    
    # 1. Health check
    print("1Ô∏è‚É£  Health check...")
    r = requests.get(f"{base_url}/health")
    assert r.status_code == 200
    print(f"   ‚úÖ {r.json()['status']}\n")
    
    # 2. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    print("2Ô∏è‚É£  –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    test_file = Path("test_logs.csv")
    test_file.write_text(
        "text,domain\n"
        "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞,house\n"
        "–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ –≤ —à–∫–æ–ª–µ,payments\n"
        "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ,okc\n"
        "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è –≤–æ–¥—ã,house\n"
        "–æ–ø–ª–∞—Ç–∏—Ç—å –∫—Ä—É–∂–æ–∫,payments\n",
        encoding="utf-8"
    )
    print("   ‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω\n")
    
    # 3. Upload
    print("3Ô∏è‚É£  –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞...")
    with open(test_file, "rb") as f:
        r = requests.post(f"{base_url}/upload", files={"file": f})
    
    assert r.status_code == 200
    file_path = r.json()["path"]
    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {file_path}\n")
    
    # 4. Process (–ø–æ–ª–Ω—ã–π pipeline)
    print("4Ô∏è‚É£  –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—ã–π pipeline...")
    print("   (ETL ‚Üí Labeler ‚Üí Augmenter ‚Üí QC ‚Üí Labeler ‚Üí DataWriter ‚Üí Storage)")
    
    r = requests.post(
        f"{base_url}/process",
        json={
            "file_path": file_path,
            "max_rows": 100,
            "balance_domains": True,
            "augment": True,
            "create_version": True
        }
    )
    
    if r.status_code == 200:
        result = r.json()
        print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"   üìä Train: {result['stats']['train_samples']}")
        print(f"   üìä Eval: {result['stats']['eval_samples']}")
        print(f"   üìä Synthetic: {result['stats']['synthetic']}")
        print(f"   üì¶ Version: {result['version_tag']}\n")
    else:
        print(f"   ‚ùå –û—à–∏–±–∫–∞: {r.status_code}")
        print(f"   {r.text}\n")
        return False
    
    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("5Ô∏è‚É£  –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    r = requests.get(f"{base_url}/stats")
    assert r.status_code == 200
    
    stats = r.json()
    print(f"   üìä Labeler:")
    print(f"      Total: {stats['labeler'].get('total_processed', 0)}")
    print(f"      Cache hits: {stats['labeler'].get('cache_hits', 0)}")
    
    print(f"   üìä Quality Control:")
    print(f"      Passed: {stats['quality_control'].get('passed', 0)}")
    print(f"      Pass rate: {stats['quality_control'].get('pass_rate', 0):.2%}")
    
    print(f"   üìä Storage:")
    print(f"      Versions: {stats['storage'].get('total_versions', 0)}\n")
    
    # 6. –°–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π
    print("6Ô∏è‚É£  –°–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π...")
    r = requests.get(f"{base_url}/versions")
    versions = r.json()
    
    for v in versions[:3]:
        print(f"   üì¶ {v['version_tag']}: {v.get('description', 'N/A')}")
    
    print(f"\n   ‚úÖ –í—Å–µ–≥–æ –≤–µ—Ä—Å–∏–π: {len(versions)}\n")
    
    # –û—á–∏—Å—Ç–∫–∞
    test_file.unlink(missing_ok=True)
    
    print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
    return True

if __name__ == "__main__":
    asyncio.run(test_full_pipeline())
```

### –ó–∞–ø—É—Å–∫:

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ API
docker-compose up -d

# 2. –ü–æ–¥–æ–∂–¥–∏—Ç–µ 5 —Å–µ–∫—É–Ω–¥

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç
python test_full_flow.py
```

---

## 5Ô∏è‚É£ –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ curl

### 1. Health Check

```bash
curl http://localhost:8000/health
```

–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:
```json
{
  "status": "healthy",
  "components": {
    "etl": "ok",
    "labeler": "ok",
    "augmenter": "ok",
    "quality_control": "ok",
    "data_writer": "ok",
    "data_storage": "ok"
  }
}
```

---

### 2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "texts": [
      "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
      "–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ –≤ —à–∫–æ–ª–µ",
      "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ"
    ]
  }'
```

–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:
```json
{
  "results": [
    {
      "text": "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞",
      "domain_id": "house",
      "confidence": 0.92,
      "top_candidates": [["house", 0.92], ["okc", 0.05], ...]
    },
    ...
  ],
  "stats": {
    "total_processed": 3,
    "cache_hits": 0,
    "llm_calls": 3
  }
}
```

---

### 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞

```bash
# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
cat > test.csv << EOF
text,domain
–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞,house
–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ,payments
—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ,okc
EOF

# –ó–∞–≥—Ä—É–∂–∞–µ–º
curl -X POST "http://localhost:8000/upload" \
  -F "file=@test.csv"

# –û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç path –∫ —Ñ–∞–π–ª—É
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:

curl -X POST "http://localhost:8000/process" \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "/app/data/uploads/test.csv",
    "balance_domains": true,
    "augment": true,
    "create_version": true
  }'
```

---

### 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

```bash
curl http://localhost:8000/stats | jq '.'
```

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:
- Labeler: cache hit rate, error rate
- Augmenter: generated samples
- Quality Control: pass rate, rejections
- Storage: versions count, size

---

## 6Ô∏è‚É£ –¢–µ—Å—Ç Quality Control (Python)

### –°–∫—Ä–∏–ø—Ç `test_quality.py`:

```python
from src.pipeline.quality_control import QualityControl, QualityControlConfig

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
qc = QualityControl(QualityControlConfig())

# –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã
test_pairs = [
    ("–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è", "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞"),  # –ú–∞–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    ("–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è", "–ø–æ–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"),    # –û–ö
    ("–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è", "–∫—É–ø–∏—Ç—å —Ö–ª–µ–±"),      # –î—Ä—É–≥–æ–π —Å–º—ã—Å–ª
    ("–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è", "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è"), # –î—É–±–ª–∏–∫–∞—Ç
]

for orig, synth in test_pairs:
    metrics = qc.compute_similarity(orig, synth)
    
    print(f"\n–û—Ä–∏–≥–∏–Ω–∞–ª: {orig}")
    print(f"–°–∏–Ω—Ç–µ—Ç–∏–∫–∞: {synth}")
    print(f"Cosine: {metrics.cosine_similarity:.3f}")
    print(f"Levenshtein: {metrics.levenshtein_distance} (ratio: {metrics.levenshtein_ratio:.3f})")
    print(f"Valid: {'‚úÖ' if metrics.is_valid else '‚ùå'}")
    if metrics.issues:
        print(f"Issues: {metrics.issues}")
```

### –ó–∞–ø—É—Å–∫:

```bash
python test_quality.py
```

---

## 7Ô∏è‚É£ Docker —Ç–µ—Å—Ç

### –ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –≤ Docker:

```bash
# 1. –°–±–æ—Ä–∫–∞
docker-compose build

# 2. –ó–∞–ø—É—Å–∫
docker-compose up -d

# 3. –õ–æ–≥–∏
docker-compose logs -f ml-pipeline

# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
# ‚úÖ LabelerAgent initialized
# ‚úÖ AugmenterAgent initialized
# ‚úÖ QualityControl initialized
# ‚úÖ DataWriter initialized
# ‚úÖ DataStorage initialized

# 4. Health check
curl http://localhost:8000/health

# 5. –¢–µ—Å—Ç API
./test_api.sh

# 6. –û—Å—Ç–∞–Ω–æ–≤–∫–∞
docker-compose down
```

---

## 8Ô∏è‚É£ –¢–µ—Å—Ç —Å Ollama (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞:

```bash
# 1. –í docker-compose.yml —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ ollama —Å–µ—Ä–≤–∏—Å

# 2. –í .env:
LLM_API_BASE=http://ollama:11434/v1
LLM_MODEL=llama3.1:8b
LLM_API_KEY=dummy

# 3. –ó–∞–ø—É—Å–∫
docker-compose up -d

# 4. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–ø–µ—Ä–≤—ã–π —Ä–∞–∑)
docker-compose exec ollama ollama pull llama3.1:8b

# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞
docker-compose exec ollama ollama list

# 6. –¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{"texts": ["–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è"]}'
```

**–†–∞–±–æ—Ç–∞–µ—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ!** üÜì

---

## 9Ô∏è‚É£ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç (–ø–æ–ª–Ω—ã–π workflow)

### –°–æ–∑–¥–∞–π—Ç–µ `test_integration.py`:

```python
import asyncio
from pathlib import Path
from src.pipeline import *
from src.config_v2 import Settings

async def integration_test():
    """–ü–æ–ª–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç"""
    
    settings = Settings.load()
    
    print("üß™ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç pipeline\n")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    test_file = Path("integration_test.csv")
    test_file.write_text(
        "text,domain\n"
        "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞,house\n"
        "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è –≤–æ–¥—ã,house\n"
        "–ø–µ—Ä–µ–¥–∞—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–∞,house\n"
        "–æ–ø–ª–∞—Ç–∏—Ç—å –ø–∏—Ç–∞–Ω–∏–µ –≤ —à–∫–æ–ª–µ,payments\n"
        "–æ–ø–ª–∞—Ç–∏—Ç—å –∫—Ä—É–∂–æ–∫,payments\n"
        "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–æ,okc\n"
        "–≥—Ä–∞—Ñ–∏–∫ –∞–≤—Ç–æ–±—É—Å–æ–≤,okc\n",
        encoding="utf-8"
    )
    
    # –®–ê–ì–ò PIPELINE:
    
    # 1. ETL
    print("1Ô∏è‚É£  ETL...")
    etl = ETLProcessor(ETLConfig())
    df = etl.process_file(test_file)
    assert len(df) == 7
    print(f"   ‚úÖ {len(df)} —Å—Ç—Ä–æ–∫\n")
    
    # 2. Labeler - –≤–∞–ª–∏–¥–∞—Ü–∏—è
    print("2Ô∏è‚É£  Labeler - –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–∫...")
    labeler = LabelerAgent(LabelerConfig(**settings.get_labeler_llm_config()))
    results = await labeler.classify_dataframe(df)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    qc = QualityControl(QualityControlConfig())
    original_items = [
        {"text": row["text"], "domain_id": row["domain"]}
        for _, row in df.iterrows()
    ]
    validation = await qc.validate_existing_labels(original_items, labeler)
    
    correct = sum(1 for v in validation if v.is_correct)
    print(f"   ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è: {correct}/{len(validation)} –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö\n")
    
    # 3. Augmenter
    print("3Ô∏è‚É£  Augmenter - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
    augmenter = AugmenterAgent(AugmenterConfig(
        **settings.get_augmenter_llm_config(),
        variants_per_sample=2
    ))
    
    high_conf = [r.dict() for r in results if r.confidence >= 0.7][:3]
    synthetic = await augmenter.augment_batch(high_conf)
    print(f"   ‚úÖ {len(synthetic)} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n")
    
    # 4. Quality Control
    print("4Ô∏è‚É£  Quality Control...")
    validated_synthetic = await qc.validate_and_label_synthetic(
        [s.dict() for s in synthetic],
        high_conf,
        labeler
    )
    
    pass_rate = len(validated_synthetic) / len(synthetic) if synthetic else 0
    print(f"   ‚úÖ {len(validated_synthetic)}/{len(synthetic)} –ø—Ä–æ—à–ª–æ (pass rate: {pass_rate:.1%})\n")
    
    # 5. DataWriter
    print("5Ô∏è‚É£  DataWriter...")
    all_items = [r.dict() for r in results] + validated_synthetic
    
    writer = DataWriter(DataWriterConfig(
        output_dir=Path("test_int_output")
    ))
    train_p, eval_p, stats = writer.write_datasets(all_items)
    print(f"   ‚úÖ Train: {stats.train_samples}, Eval: {stats.eval_samples}\n")
    
    # 6. DataStorage
    print("6Ô∏è‚É£  DataStorage...")
    storage = DataStorage(DataStorageConfig(
        storage_dir=Path("test_int_storage")
    ))
    
    from src.pipeline.data_storage import VersionStatus
    version = storage.commit_version(
        train_p, eval_p,
        description="Integration test",
        status=VersionStatus.DRAFT
    )
    print(f"   ‚úÖ Version: {version.version_tag}\n")
    
    # –û—á–∏—Å—Ç–∫–∞
    import shutil
    test_file.unlink()
    shutil.rmtree("test_int_output", ignore_errors=True)
    shutil.rmtree("test_int_storage", ignore_errors=True)
    
    print("üéâ –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ –£–°–ü–ï–®–ï–ù!")
    return True

asyncio.run(integration_test())
```

---

## üîü Checklist –ø–µ—Ä–µ–¥ production

- [ ] `python test_pipeline.py` - –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç
- [ ] `./test_api.sh` - –≤—Å–µ endpoints –æ—Ç–≤–µ—á–∞—é—Ç
- [ ] Swagger UI –¥–æ—Å—Ç—É–ø–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Quality Control —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [ ] –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–µ—Ç –≤–µ—Ä—Å–∏–∏
- [ ] –õ–æ–≥–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –æ—à–∏–±–æ–∫
- [ ] Health check –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç "healthy"
- [ ] Docker –æ–±—Ä–∞–∑ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
- [ ] –¢–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏

### –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ 100 –ª–æ–≥–æ–≤:

```json
{
  "labeler": {
    "total_processed": 100,
    "cache_hits": 0,
    "llm_calls": 100,
    "low_confidence_count": 15
  },
  "quality_control": {
    "total_validated": 210,
    "passed": 175,
    "pass_rate": 0.83,
    "rejected_low_similarity": 15,
    "rejected_high_similarity": 10,
    "rejected_levenshtein": 10
  },
  "storage": {
    "total_versions": 1,
    "total_size_mb": 0.5
  }
}
```

---

## ‚ö†Ô∏è Troubleshooting

### API –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env
cat .env

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏
docker-compose logs ml-pipeline

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ—Ä—Ç
netstat -an | grep 8000
```

### LLM –æ—à–∏–±–∫–∏

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á
echo $LLM_API_KEY

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
curl -I https://api.openai.com/v1/models
```

### Quality Control –æ—Ç–∫–ª–æ–Ω—è–µ—Ç –≤—Å—ë

```bash
# –°–Ω–∏–∑—å—Ç–µ —Å—Ç—Ä–æ–≥–æ—Å—Ç—å –≤ config
QC_STRICT_MODE=false
QC_MIN_COSINE_SIMILARITY=0.2
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

1. **–ù–∞—á–Ω–∏—Ç–µ —Å** `python test_pipeline.py` - –±—ã—Å—Ç—Ä–æ, ~1 –º–∏–Ω—É—Ç–∞
2. **–ó–∞—Ç–µ–º** Swagger UI - –≤–∏–∑—É–∞–ª—å–Ω–æ, –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ
3. **–ü–æ—Ç–æ–º** `./test_api.sh` - –ø–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ endpoints
4. **–§–∏–Ω–∞–ª—å–Ω–æ** —Ç–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

---

**–£—Å–ø–µ—à–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è! üß™‚ú®**

